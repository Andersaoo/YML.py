import os
import json
import yaml
import requests
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
import re

import config


@dataclass
class GitLabConfig:
    """GitLab API configuration / –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è GitLab API"""
    token: str
    url: str = "https://gitlab.com"
    group_path: str = ""
    max_projects: int = 500


class GitLabAPIClient:
    """GitLab API client with retries and rate limit handling / –ö–ª–∏–µ–Ω—Ç GitLab API —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –ª–∏–º–∏—Ç–æ–≤"""

    def __init__(self, config: GitLabConfig):
        self.config = config
        self.session = requests.Session()
        self.session.headers.update({"PRIVATE-TOKEN": config.token, "Content-Type": "application/json"})
        self.timeout = 30
        self.max_retries = 3

    def make_request(self, url: str, params: Dict = None, method: str = "GET") -> Optional[requests.Response]:
        """Execute request with exponential backoff on timeout/rate limit / –í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π"""
        for attempt in range(self.max_retries):
            try:
                if method == "GET":
                    response = self.session.get(url, params=params, timeout=self.timeout)
                else:  # POST
                    response = self.session.post(url, json=params, timeout=self.timeout)

                if response and response.status_code == 200:
                    return response
                elif response and response.status_code == 429:  # Rate limit
                    wait_time = 2 ** (attempt + 1)
                    print(f"‚ö†Ô∏è  Rate limit, waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"‚ö†Ô∏è  HTTP {response.status_code} for {url}")
                    return None
            except requests.exceptions.Timeout:
                print(f"‚ö†Ô∏è  Timeout attempt {attempt + 1}/{self.max_retries}")
                time.sleep(2 ** attempt)
            except Exception as e:
                print(f"‚ùå Request error: {e}")
                return None
        return None

    def test_connection(self) -> bool:
        """Verify GitLab connectivity / –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å GitLab"""
        url = f"{self.config.url}/api/v4/version"
        response = self.make_request(url)
        if response:
            print(f"‚úÖ Connected to GitLab {response.json().get('version')}")
            return True
        return False

    def get_group_id(self, group_path: str) -> Optional[int]:
        """Get group ID by full path / –ü–æ–ª—É—á–∏—Ç—å ID –≥—Ä—É–ø–ø—ã –ø–æ –ø—É—Ç–∏"""
        if not group_path:
            return None
        encoded = group_path.replace('/', '%2F')
        url = f"{self.config.url}/api/v4/groups/{encoded}"
        response = self.make_request(url)
        return response.json().get('id') if response else None

    def get_all_projects(self, group_id: Optional[int] = None) -> List[Dict]:
        """Fetch all projects (optionally under a group) / –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –ø—Ä–æ–µ–∫—Ç—ã (–≤–æ–∑–º–æ–∂–Ω–æ, –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã)"""
        all_projects = []
        page = 1
        print("üìã Fetching project list...")
        while True:
            url = f"{self.config.url}/api/v4/groups/{group_id}/projects" if group_id else f"{self.config.url}/api/v4/projects"
            params = {"per_page": 50, "page": page, "simple": True, "order_by": "last_activity_at", "sort": "desc"}
            if group_id:
                params["include_subgroups"] = True

            response = self.make_request(url, params)
            if not response:
                break

            projects = response.json()
            if not projects:
                break

            all_projects.extend(projects)
            print(f"  üìÑ Loaded {len(all_projects)} projects")

            if self.config.max_projects and len(all_projects) >= self.config.max_projects:
                print(f"‚ö†Ô∏è  Reached limit of {self.config.max_projects} projects")
                all_projects = all_projects[:self.config.max_projects]
                break

            if 'next' not in response.links:
                break
            page += 1
            time.sleep(0.1)  # be gentle to API

        return all_projects

    def get_project_files(self, project_id: int) -> List[Dict]:
        """Get recursive file tree of a project / –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ –¥–µ—Ä–µ–≤–æ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞"""
        url = f"{self.config.url}/api/v4/projects/{project_id}/repository/tree"
        params = {"recursive": True, "per_page": 100}
        response = self.make_request(url, params)
        return response.json() if response else []

    def get_file_content(self, project_id: int, file_path: str, ref: str = "main") -> Optional[str]:
        """Get raw content of a file / –ü–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞"""
        encoded = file_path.replace('/', '%2F')
        url = f"{self.config.url}/api/v4/projects/{project_id}/repository/files/{encoded}/raw"
        response = self.make_request(url, {"ref": ref})
        return response.text if response else None


class YAMLAnalyzer:
    """YAML parsing and image tag extraction / –†–∞–∑–±–æ—Ä YAML –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ –æ–±—Ä–∞–∑–æ–≤"""

    @staticmethod
    def extract_image_tag(image_string: str) -> str:
        """Extract tag from docker image string (handles variables) / –ò–∑–≤–ª–µ—á—å —Ç–µ–≥ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –æ–±—Ä–∞–∑–∞ (—Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏)"""
        if not image_string:
            return ""
        image_string = image_string.strip()
        if ':' in image_string:
            tag = image_string.split(':')[-1]
            # strip variable wrappers like ${...} or ${{...}}
            if tag.startswith('${') and tag.endswith('}'):
                tag = tag[2:-1]
            elif tag.startswith('${{') and tag.endswith('}}'):
                tag = tag[3:-2]
            return tag
        return image_string

    @staticmethod
    def find_services_in_yaml(content: str) -> Dict[str, str]:
        """Recursively find all 'image' fields in YAML / –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –Ω–∞–π—Ç–∏ –≤—Å–µ –ø–æ–ª—è 'image' –≤ YAML"""
        services = {}
        try:
            data = yaml.safe_load(content)
            if not data:
                return services

            def recursive_search(obj, path=""):
                if isinstance(obj, dict):
                    if 'image' in obj and isinstance(obj['image'], str):
                        tag = YAMLAnalyzer.extract_image_tag(obj['image'])
                        name = path or next((obj.get(n) for n in ['name', 'container_name', 'service'] if n in obj), "unnamed")
                        services[name] = tag
                    for k, v in obj.items():
                        if k not in ['image', 'build', 'networks', 'volumes', 'ports', 'environment']:
                            recursive_search(v, f"{path}.{k}" if path else k)
                elif isinstance(obj, list):
                    for i, item in enumerate(obj):
                        recursive_search(item, f"{path}[{i}]")

            recursive_search(data)
        except yaml.YAMLError:
            # fallback to regex for malformed YAML
            services = YAMLAnalyzer.extract_images_via_regex(content)
        except Exception as e:
            print(f"‚ö†Ô∏è  YAML analysis error: {e}")
        return services

    @staticmethod
    def extract_images_via_regex(content: str) -> Dict[str, str]:
        """Fallback regex-based extraction / –ó–∞–ø–∞—Å–Ω–æ–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è"""
        services = {}
        patterns = [
            r'^\s*image\s*:\s*["\']?([^"\'\n]+)["\']?',
            r'"image"\s*:\s*"([^"]+)"',
            r"'image'\s*:\s*'([^']+)'",
            r'^\s*(\w+)\s*:\s*\n\s+image\s*:\s*["\']?([^"\'\n]+)["\']?',
        ]
        for pattern in patterns:
            for match in re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE):
                if len(match.groups()) == 1:
                    services[f"service_{len(services)}"] = YAMLAnalyzer.extract_image_tag(match.group(1))
                elif len(match.groups()) == 2:
                    services[match.group(1)] = YAMLAnalyzer.extract_image_tag(match.group(2))
        return services

    @staticmethod
    def normalize_service_name(name: str) -> str:
        """Clean up service name: remove brackets, extra underscores / –û—á–∏—Å—Ç–∏—Ç—å –∏–º—è —Å–µ—Ä–≤–∏—Å–∞"""
        if not name:
            return ""
        name = name.replace('-', '_').replace('.', '_')
        if name.startswith('services_'):
            name = name[9:]
        name = re.sub(r'\[.*?\]', '', name)
        name = re.sub(r'_+', '_', name)
        return name.strip('_')


class GitLabServiceCollector:
    """Main collector orchestrator / –û—Å–Ω–æ–≤–Ω–æ–π —Å–±–æ—Ä—â–∏–∫"""

    def __init__(self, config: GitLabConfig):
        self.config = config
        self.api = GitLabAPIClient(config)
        self.analyzer = YAMLAnalyzer()
        self.stats = {"total_projects": 0, "projects_with_yaml": 0, "total_yaml_files": 0, "total_services": 0, "errors": 0}
        self.results = {}

    def analyze_project(self, project: Dict) -> Optional[Dict]:
        """Analyze a single project: fetch YAMLs, extract services / –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω –ø—Ä–æ–µ–∫—Ç"""
        pid = project['id']
        name = project['name']
        print(f"  üîç Analyzing project: {name}")

        files = self.api.get_project_files(pid)
        if not files:
            print("    ‚ö†Ô∏è  No files or access error")
            return None

        yaml_files = []
        for f in files:
            if f.get('type') == 'blob' and f['name'].endswith(('.yml', '.yaml')):
                if f['name'] not in ['.gitlab-ci.yml', 'docker-compose.yml', 'docker-compose.yaml']:
                    yaml_files.append({'path': f['path'], 'name': f['name']})

        if not yaml_files:
            print("    ‚ÑπÔ∏è  No YAML files")
            return None

        print(f"    üìÑ YAML files: {len(yaml_files)}")
        project_services = {}

        for yf in yaml_files:
            content = self.api.get_file_content(pid, yf['path'])
            if not content:
                print(f"      ‚ùå Failed to get {yf['name']}")
                self.stats["errors"] += 1
                continue

            services = self.analyzer.find_services_in_yaml(content)
            if services:
                norm = {self.analyzer.normalize_service_name(s): t for s, t in services.items()}
                key = yf['name'].replace('.yml', '').replace('.yaml', '')
                if key.startswith('services_'):
                    key = key[9:]
                project_services[key] = norm
                self.stats["total_yaml_files"] += 1
                self.stats["total_services"] += len(services)
                print(f"      ‚úÖ {yf['name']}: {len(services)} services")
            else:
                print(f"      ‚ÑπÔ∏è  {yf['name']}: no services found")

        if project_services:
            self.stats["projects_with_yaml"] += 1
            return {"project_id": pid, "project_name": name, "services": project_services}
        return None

    def collect_all_services(self, use_threads: bool = True, max_workers: int = 5):
        """Collect services from all rojects (optionally parallel) / –°–û–±—Ä–∞—Ç—å —Å–µ—Ä–≤–∏—Å—ã –∏–∑ –≤—Å–µ—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤"""
        print("=" * 70)
        print("üöÄ STARTING GITLAB DATA COLLECTION")
        print("=" * 70)

        if not self.api.test_connection():
            print("‚ùå Cannot connect to GitLab API")
            return

        group_id = None
        if self.config.group_path:
            group_id = self.api.get_group_id(self.config.group_path)
            if group_id:
                print(f"‚úÖ Group found: {self.config.group_path} (ID: {group_id})")
            else:
                print(f"‚ö†Ô∏è  Group not found: {self.config.group_path}")

        projects = self.api.get_all_projects(group_id)
        if not projects:
            print("‚ùå No projects retrieved")
            return

        self.stats["total_projects"] = len(projects)
        print(f"üìä Total projects to analyze: {len(projects)}")

        if use_threads and len(projects) > 1:
            print(f"‚ö° Using threads ({max_workers} workers)")
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = {executor.submit(self.analyze_project, p): p for p in projects}
                for f in as_completed(futures):
                    try:
                        res = f.result(timeout=60)
                        if res:
                            self.results[res["project_name"]] = res["services"]
                    except Exception as e:
                        print(f"‚ùå Error analyzing project {futures[f].get('name')}: {e}")
                        self.stats["errors"] += 1
        else:
            for p in projects:
                res = self.analyze_project(p)
                if res:
                    self.results[res["project_name"]] = res["services"]

        self.print_statistics()

    def print_statistics(self):
        """Print collection statistics / –í—ã–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        print("\n" + "=" * 70)
        print("üìä STATISTICS")
        print("=" * 70)
        for k, v in self.stats.items():
            print(f"{k.replace('_',' ').title()}: {v}")
        if self.results:
            print(f"\n‚úÖ Data collected from {len(self.results)} projects")
        else:
            print("\n‚ùå No data collected")

    def save_results(self, output_format: str = "all", output_dir: str = "."):
        """Save results to files (json/txt/csv) / –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã"""
        if not self.results:
            print("‚ùå No data to save")
            return

        os.makedirs(output_dir, exist_ok=True)
        ts = time.strftime("%Y%m%d_%H%M%S")

        if output_format in ("json", "all"):
            data = {
                "metadata": {
                    "collected_at": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "gitlab_group": self.config.group_path or "all accessible projects",
                    "statistics": self.stats
                },
                "projects": self.results
            }
            path = os.path.join(output_dir, f"gitlab_services_{ts}.json")
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            print(f"üíæ JSON saved: {path}")

        if output_format in ("text", "all"):
            path = os.path.join(output_dir, f"services_structure_{ts}.txt")
            with open(path, 'w', encoding='utf-8') as f:
                for proj, services in self.results.items():
                    f.write(f"{proj}\n")
                    for file_key, svc_dict in services.items():
                        f.write(f"‚Äî‚Äî‚Äî {file_key}\n")
                        for svc, tag in svc_dict.items():
                            f.write(f"‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî {svc}: {tag}\n")
                        f.write("\n")
            print(f"üìù Text file saved: {path}")

        if output_format in ("csv", "all"):
            path = os.path.join(output_dir, f"services_{ts}.csv")
            with open(path, 'w', encoding='utf-8') as f:
                f.write("Project,File,Service,Tag\n")
                for proj, services in self.results.items():
                    for file_key, svc_dict in services.items():
                        for svc, tag in svc_dict.items():
                            f.write(f"{proj},{file_key},{svc},{tag}\n")
            print(f"üìä CSV saved: {path}")

    def print_structure(self):
        """Print hierarchical structure to console / –í–´–≤–µ—Å—Ç–∏ –∏–µ—Ä–∞—Ä—Ö–∏—é –≤ –∫–æ–Ω—Å–æ–ª—å"""
        if not self.results:
            print("‚ùå No data to display")
            return
        print("\n" + "=" * 70)
        print("üèóÔ∏è  SERVICE STRUCTURE")
        print("=" * 70)
        for proj, services in self.results.items():
            print(proj)
            for file_key, svc_dict in services.items():
                print(f"‚Äî‚Äî‚Äî {file_key}")
                for svc, tag in svc_dict.items():
                    print(f"‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî {svc}: {tag}")
                print()


def main():
    print("=" * 70)
    print("üöÄ GITLAB SERVICES COLLECTOR")
    print("=" * 70)

    cfg = config.load_config()
    token = cfg.get("gitlab_token")
    if not token:
        print("‚ùå GITLAB_PRIVATE_TOKEN not set. Please provide it in .env file.")
        return

    gitlab_config = GitLabConfig(
        token=token,
        url=cfg.get("gitlab_url", "https://gitlab.com"),
        group_path=cfg.get("group_path", ""),
        max_projects=cfg.get("max_projects", 500)
    )

    collector = GitLabServiceCollector(gitlab_config)
    print("\n" + "=" * 70)
    print("‚ö° COLLECTING DATA")
    print("=" * 70)

    collector.collect_all_services(use_threads=True, max_workers=5)

    if not collector.results:
        print("\n‚ùå No data collected.")
        return

    collector.print_structure()

    print("\n" + "=" * 70)
    print("üíæ SAVE RESULTS")
    print("=" * 70)
    print("Choose format:\n  1. All (JSON, TXT, CSV)\n  2. Text only\n  3. JSON only\n  4. CSV only")
    choice = input("Your choice (1-4): ").strip()
    out_dir = cfg.get("output_dir", "results")
    formats = {"1": "all", "2": "text", "3": "json", "4": "csv"}
    collector.save_results(formats.get(choice, "all"), out_dir)
    print("\n‚úÖ Done.")


if __name__ == "__main__":
    main()